defaults:
  - base_cfg
  - _self_
  - data: mnist
  - mode: ???
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  mode: RUN
  output_subdir: null
  run:
    dir: .

paths:
  root: ${runtime.root}
  data: ${runtime.root}/_data
  raw_data: ${runtime.root}/_data/_raw
  output: ${runtime.root}/_output/mnist_diffusion
  weights: ${runtime.root}/_weights

execution:
  epochs: 20
  seed: 42
  start_from: LATEST
  start_weights: null

output:
  save_checkpoints: true
  out_dir: ${runtime.root}/_output
  wandb_project: cdnp
  log_gradients: false
  gradient_log_freq: 100
  use_tqdm: true
  log_level: INFO
  plotter:
   _target_: cdnp.plot.plotter.Plotter
   _partial_: true
   device: ${runtime.device}
   num_samples: 4
   num_classes: ${data.num_classes}
   ws_test: [0.0, 1.0]

rng:
  generator:
    _target_: torch.Generator
    device: ${runtime.device}

  cpu_generator:
    _target_: torch.Generator
    device: cpu

loss:
  _target_: torch.nn.NLLLoss

model:
  _target_: cdnp.model.ddpm.DDPM
  nn_model:
    _target_: cdnp.model.unet.ContextUnet
    in_channels: ${data.in_channels}
    n_feat: 128
    n_classes: ${data.num_classes}
  betas: [1e-4, 0.02]
  n_T: 400
  device: ${runtime.device}
  drop_prob: 0.1

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-4

scheduler:
  _target_: torch.optim.lr_scheduler.LinearLR
  _partial_: true
  start_factor: 1.0
  end_factor: 0.0
  total_iters: ${execution.epochs}

data:
  dataset:
    paths: ${paths}
    val_fraction: 0.1
  cache: false
  trainloader:
    _target_: torch.utils.data.DataLoader
    _partial_: true
    batch_size: 64
    shuffle: true
    num_workers: 0
    multiprocessing_context: null
  testloader:
    _target_: torch.utils.data.DataLoader
    _partial_: true
    batch_size: 1000
    shuffle: false
    num_workers: 0
    multiprocessing_context: null
