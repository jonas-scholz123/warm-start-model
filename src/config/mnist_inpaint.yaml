defaults:
  - base
  - data: mnist
  - _self_

model:
  model:
    block_out_channels: [64, 128, 256]
    down_block_types:
      - DownBlock2D
      - AttnDownBlock2D
      - AttnDownBlock2D
    up_block_types:
      - AttnUpBlock2D
      - AttnUpBlock2D
      - UpBlock2D
    out_channels: 1 # Just the greyscale image
    num_class_embeds: null # No class labels for this task
  
execution:
  epochs: 20

data:
  in_channels: 3 # noised greyscale image + masked input + mask
  preprocess_fn:
    _target_: cdnp.task.preprocess_inpaint
    _partial_: true
    # TODO: this should be a singleton, injected in Experiment.from_config
    gen: ${rng.cpu_generator}
    min_frac: 0.1
    max_frac: 0.5

# TODO
output:
  plotter: null